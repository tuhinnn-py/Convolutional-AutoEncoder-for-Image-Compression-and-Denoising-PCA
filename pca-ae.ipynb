{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Demonstration :: Principal Component Ananlysis and Covariance**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport math,datetime\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing,svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom matplotlib import style\nimport pickle\nimport quandl\n\nstyle.use('ggplot')\nquandl.ApiConfig.api_key='4YW-QTzBhE_R2tmcVyR6'\ndf=quandl.get('WIKI/GOOGL')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\ncol=df.columns\nX=np.array(df)\nX=preprocessing.scale(X)\npca=PCA()\npca.fit(X)\ncov=pca.get_covariance()\nnp.fill_diagonal(cov,0.0)\nco=cov.astype('int32')\nco=np.where(co==1)\nx_co,y_co=co[0],co[1]\nfor x,y in zip(x_co,y_co):\n    print(col[x],col[y],cov[x][y],sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df[['Adj. High','Adj. Low','Adj. Open','Adj. Close','Volume']]\ndf['HL_PCT']=(df['Adj. High']-df['Adj. Low'])*100.0/df['Adj. Low']\ndf['PCT_Change']=(df['Adj. Close']-df['Adj. Open'])*100.0/df['Adj. Open']\ndf=df[['Adj. Close','HL_PCT','PCT_Change','Volume']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_col='Adj. Close'\nforecast_out=int(math.ceil(0.01*len(df)))\ndf['Label']=df[forecast_col].shift(-forecast_out)\n'''\nX_lately=np.array(df[-forecast_out:])\ndf.dropna(axis=0,inplace=True)\nX=np.array(df.drop('Label',axis=1))\ny=np.array(df['Label'])\n''' \nX=np.array(df.drop('Label',axis=1))\nX=preprocessing.scale(X)\nX_lately=X[-forecast_out:]\nX=X[:-forecast_out]\ndf.dropna(axis=0,inplace=True)\ny=np.array(df['Label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X=preprocessing.scale(X)\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n#f=open('LinearRegression.pickle','rb')\nclf=LinearRegression(n_jobs=-1)\nclf.fit(X_train,y_train)\nacc_=clf.score(X_test,y_test)\nprint(acc_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_set=clf.predict(X_lately)\nplt.plot(df['Label'][:35])\nlast_date=df.iloc[-1].name\nlast_unix=last_date.timestamp()\none_day=86400\nnext_unix=last_unix+one_day\nfor i in forecast_set:\n    next_day=datetime.datetime.fromtimestamp(next_unix)\n    next_unix+=one_day\n    df.loc[next_day]=[np.nan for _ in range(len(df.columns)-1)]+[i]\nplt.plot(df['Label'][:25])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**AutoEncoders**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Model\nfrom keras.layers import Dense,Input,Activation\nfrom keras.metrics import categorical_crossentropy\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport pickle\nstyle.use('ggplot')\nX=np.arange(1,7)\ny=np.array([5,4,6,5,6,7])\ninput_param=Input(shape=(1,))\nhidden_layer=Dense(16,activation='linear')(input_param)\noutput_layer=Dense(1,activation='linear')(hidden_layer)\nclf=Model(input_param,output_layer)\nloss_fn=keras.losses.MeanSquaredError()\nclf.compile(optimizer='Adam',loss=loss_fn)\nclf.fit(X,y,verbose=2,epochs=2000,batch_size=1,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,Conv2DTranspose,BatchNormalization,LeakyReLU\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef get_data(filename,data):\n    for file in os.listdir(filename):\n        img=load_img(os.path.join(filename,file),target_size=(128,128,3))\n        img=img_to_array(img)\n        data.append(img)\n    return data\ndataset=list()\npath='/kaggle/input/natural-images/natural_images'\nfor file_dir in os.listdir(path):\n    dataset=get_data(os.path.join(path,file_dir),dataset)\ndataset=np.asarray(dataset,dtype='float32')\ndataset=dataset/255\ndataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Add,Activation\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow as tf\ndef resnet_block(n_filters,ip_model):\n    d=Conv2D(n_filters,(3,3),padding='same')(ip_model)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    \n    d=Conv2D(n_filters,(3,3),padding='same')(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    \n    d=Add()([d,ip_model])\n    return d\ndef load_mod():\n    path='/kaggle/input/aemodel/ae.h5'\n    ae=get_model(dataset[1].shape,8)\n    ae.load_weights(path)\n    \n    de=tf.keras.models.Sequential()\n    for layer in ae.layers[70:]:\n        de.add(layer)\n    de.build((1,64,64,256))\n    \n    en=Model(ae.input,ae.layers[69].output)\n    return ae,en,de\n\ndef get_model(ip_shape,n_resnets):\n    ip=Input(shape=ip_shape)\n    \n    d=Conv2D(128,(3,3),strides=2,padding='same')(ip)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    \n    d=Conv2D(256,(3,3),strides=2,padding='same')(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n\n    for i in range(n_resnets):\n        d=resnet_block(256,d)\n        \n    encoded=resnet_block(256,d)\n    \n    d=Conv2DTranspose(128,(3,3),strides=2,padding='same')(encoded)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    \n    d=Conv2DTranspose(64,(3,3),strides=2,padding='same')(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n\n    d=Conv2DTranspose(3,(3,3),padding='same')(d)\n    d=BatchNormalization()(d)\n    decoded=Activation('relu')(d)\n    \n    autoencoder=Model(ip,decoded)\n    return autoencoder\n\nae,encoder,decoder=load_mod()\n\ndef ssim_loss(y_true,y_pred):\n    return tf.reduce_mean(tf.image.ssim(y_true,y_pred,1.0))\n\ncp=ModelCheckpoint(filepath='/kaggle/working/ae',save_best_only=True,monitor='val_acc',mode=' max',save_weights_only=True)\nae.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n#ae.fit(dataset,dataset,verbose=2,epochs=100,batch_size=64,shuffle=True,validation_split=0.2,callbacks=[cp])\n#ae.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_samples=5\nsample_data=dataset[np.random.randint(0,6888,5)]\npredictions=np.asarray(ae.predict(sample_data))\nfor i in range(n_samples):\n    plt.subplot(2,n_samples,i+1)\n    plt.imshow(sample_data[i])\nfor i in range(n_samples):\n    plt.subplot(2,n_samples,i+6)\n    plt.imshow(predictions[i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ae.save_weights('/kaggle/working/ae.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1=styles[0]\nplt.subplot(1,3,1)\nplt.imshow(data1)\n\ndata2=styles[1]\nplt.subplot(1,3,2)\nplt.imshow(data2)\n\ndata1_en=encoder.predict(tf.expand_dims(data1,axis=0))\ndata2_en=encoder.predict(tf.expand_dims(data2,axis=0))\ndata_dec=decoder.predict(np.add(data1_en,data2_en*0.8))[0]\nplt.subplot(1,3,3)\nplt.imshow(data_dec)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}