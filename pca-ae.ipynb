{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\n'''\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n'''\npath='/kaggle/input/images-for-style-transfer/Data/Artworks'\nstyles=list()\nfor file in os.listdir(path):\n    img=load_img(os.path.join(path,file),target_size=(128,128,3))\n    styles.append(img_to_array(img))\nstyles=np.asarray(styles)/255\nplt.imshow(styles[1])\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport math,datetime\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing,svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom matplotlib import style\nimport pickle\nimport quandl\n\nstyle.use('ggplot')\nquandl.ApiConfig.api_key='4YW-QTzBhE_R2tmcVyR6'\ndf=quandl.get('WIKI/GOOGL')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\ncol=df.columns\nX=np.array(df)\nX=preprocessing.scale(X)\npca=PCA()\npca.fit(X)\ncov=pca.get_covariance()\nnp.fill_diagonal(cov,0.0)\nco=cov.astype('int32')\nco=np.where(co==1)\nx_co,y_co=co[0],co[1]\nfor x,y in zip(x_co,y_co):\n    print(col[x],col[y],cov[x][y],sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df[['Adj. High','Adj. Low','Adj. Open','Adj. Close','Volume']]\ndf['HL_PCT']=(df['Adj. High']-df['Adj. Low'])*100.0/df['Adj. Low']\ndf['PCT_Change']=(df['Adj. Close']-df['Adj. Open'])*100.0/df['Adj. Open']\ndf=df[['Adj. Close','HL_PCT','PCT_Change','Volume']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_col='Adj. Close'\nforecast_out=int(math.ceil(0.01*len(df)))\ndf['Label']=df[forecast_col].shift(-forecast_out)\n'''\nX_lately=np.array(df[-forecast_out:])\ndf.dropna(axis=0,inplace=True)\nX=np.array(df.drop('Label',axis=1))\ny=np.array(df['Label'])\n''' \nX=np.array(df.drop('Label',axis=1))\nX=preprocessing.scale(X)\nX_lately=X[-forecast_out:]\nX=X[:-forecast_out]\ndf.dropna(axis=0,inplace=True)\ny=np.array(df['Label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X=preprocessing.scale(X)\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n#f=open('LinearRegression.pickle','rb')\nclf=LinearRegression(n_jobs=-1)\nclf.fit(X_train,y_train)\nacc_=clf.score(X_test,y_test)\nprint(acc_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_set=clf.predict(X_lately)\nplt.plot(df['Label'][:35])\nlast_date=df.iloc[-1].name\nlast_unix=last_date.timestamp()\none_day=86400\nnext_unix=last_unix+one_day\nfor i in forecast_set:\n    next_day=datetime.datetime.fromtimestamp(next_unix)\n    next_unix+=one_day\n    df.loc[next_day]=[np.nan for _ in range(len(df.columns)-1)]+[i]\nplt.plot(df['Label'][:25])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Model\nfrom keras.layers import Dense,Input,Activation\nfrom keras.metrics import categorical_crossentropy\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport pickle\nstyle.use('ggplot')\nX=np.arange(1,7)\ny=np.array([5,4,6,5,6,7])\ninput_param=Input(shape=(1,))\nhidden_layer=Dense(16,activation='linear')(input_param)\noutput_layer=Dense(1,activation='linear')(hidden_layer)\nclf=Model(input_param,output_layer)\nloss_fn=keras.losses.MeanSquaredError()\nclf.compile(optimizer='Adam',loss=loss_fn)\nclf.fit(X,y,verbose=2,epochs=2000,batch_size=1,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,Conv2DTranspose,BatchNormalization,LeakyReLU\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef get_data(filename,data):\n    for file in os.listdir(filename):\n        img=load_img(os.path.join(filename,file),target_size=(128,128,3))\n        img=img_to_array(img)\n        data.append(img)\n    return data\ndataset=list()\npath='/kaggle/input/natural-images/natural_images'\nfor file_dir in os.listdir(path):\n    dataset=get_data(os.path.join(path,file_dir),dataset)\ndataset=np.asarray(dataset,dtype='float32')\ndataset=dataset/255\ndataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Add,Activation\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow as tf\ndef resnet_block(n_filters,ip_model):\n    d=Conv2D(n_filters,(3,3),padding='same')(ip_model)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    \n    d=Conv2D(n_filters,(3,3),padding='same')(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    \n    d=Add()([d,ip_model])\n    return d\ndef load_mod():\n    path='/kaggle/input/aemodel/ae.h5'\n    ae=get_model(dataset[1].shape,8)\n    ae.load_weights(path)\n    \n    de=tf.keras.models.Sequential()\n    for layer in ae.layers[70:]:\n        de.add(layer)\n    de.build((1,64,64,256))\n    \n    en=Model(ae.input,ae.layers[69].output)\n    return ae,en,de\n\ndef get_model(ip_shape,n_resnets):\n    ip=Input(shape=ip_shape)\n    '''\n    d=Conv2D(64,(3,3),padding='same')(ip)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    '''\n    d=Conv2D(128,(3,3),strides=2,padding='same')(ip)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    \n    d=Conv2D(256,(3,3),strides=2,padding='same')(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    '''\n    d=Conv2D(256,(3,3),padding='same')(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    '''\n    for i in range(n_resnets):\n        d=resnet_block(256,d)\n        \n    encoded=resnet_block(256,d)\n    \n    d=Conv2DTranspose(128,(3,3),strides=2,padding='same')(encoded)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    \n    d=Conv2DTranspose(64,(3,3),strides=2,padding='same')(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    '''\n    d=Conv2DTranspose(64,(3,3),strides=2,padding='same')(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    '''\n    d=Conv2DTranspose(3,(3,3),padding='same')(d)\n    d=BatchNormalization()(d)\n    decoded=Activation('relu')(d)\n    \n    #e=Input(shape=(64,64,256))\n    autoencoder=Model(ip,decoded)\n    return autoencoder\n\nae,encoder,decoder=load_mod()\n\ndef ssim_loss(y_true,y_pred):\n    return tf.reduce_mean(tf.image.ssim(y_true,y_pred,1.0))\n\ncp=ModelCheckpoint(filepath='/kaggle/working/ae',save_best_only=True,monitor='val_acc',mode=' max',save_weights_only=True)\nae.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n#ae.fit(dataset,dataset,verbose=2,epochs=100,batch_size=64,shuffle=True,validation_split=0.2,callbacks=[cp])\n#ae.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_samples=5\nsample_data=dataset[np.random.randint(0,6888,5)]\npredictions=np.asarray(ae.predict(sample_data))\nfor i in range(n_samples):\n    plt.subplot(2,n_samples,i+1)\n    plt.imshow(sample_data[i])\nfor i in range(n_samples):\n    plt.subplot(2,n_samples,i+6)\n    plt.imshow(predictions[i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ae.save_weights('/kaggle/working/ae.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1=styles[0]\nplt.subplot(1,3,1)\nplt.imshow(data1)\n\ndata2=styles[1]\nplt.subplot(1,3,2)\nplt.imshow(data2)\n\ndata1_en=encoder.predict(tf.expand_dims(data1,axis=0))\ndata2_en=encoder.predict(tf.expand_dims(data2,axis=0))\ndata_dec=decoder.predict(np.add(data1_en,data2_en*0.8))[0]\nplt.subplot(1,3,3)\nplt.imshow(data_dec)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}